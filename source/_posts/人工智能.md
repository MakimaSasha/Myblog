---
title: 人工智能
date: 2023-03-11
tag: AI
---

## 机器学习

### 决策树

```markdown
决策树是一种基于树形结构的机器学习算法，它可以用来预测一个目标变量的值。决策树通过对数据集进行分类和分割来构建树形结构，每个节点代表一个特征，每个分支代表一个决策或者一个特征的取值。
```

### 贝叶斯分类器

```markdown
贝叶斯分类器是一种基于贝叶斯定理的分类算法，它通过计算每个类别的概率来预测一个新数据点的类别。贝叶斯分类器的核心思想是基于训练数据集中每个类别的先验概率，计算出每个类别的后验概率，并选择后验概率最大的类别作为预测结果。
```

### 聚类

```markdown
类是一种无监督学习算法，它将相似的数据点分组到同一个簇中。聚类算法可以用来发现数据中的模式和结构，并且可以用于数据降维和数据可视化等领域。
```

### 支持向量机

```python
支持向量机（Support Vector Machine，SVM）是一种基于统计学习理论的二分类模型。它通过将高维空间中的数据点映射到低维空间中，从而实现在非线性可分的情况下进行分类。SVM的核心思想是找到一个最优的超平面，使得该超平面能够将不同类别的样本点分隔开来，并且使得样本点到该超平面的距离最大化。

SVM的优点在于它具有较强的泛化能力和鲁棒性，能够处理高维数据和非线性问题。在实际应用中，SVM被广泛应用于图像分类、文本分类、生物信息学等领域。
```

### 概念

```markdown
“机器学习是一类强大的可以从经验中学习的技术。 通常采用观测数据或与环境交互的形式，机器学习算法会积累更多的经验，其性能也会逐步提高。利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。 相反，我们只需要定义一个灵活的程序算法，其输出由许多参数（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数通过某种性能度量方式来达到完成任务的最佳性能。”
```

### Stable Diffusion Model

```markdown
稳定扩散模型生成图像的步骤如下：

    1.确定图像的基本要素：确定生成图像的大小、分辨率、颜色等基本要素。

    2.设定扩散模型的参数：选择合适的扩散系数、分布参数等模型参数，以便生成所需的图形。

    3.初始化粒子分布：将粒子分布在图像的初始位置上。

    4.进行随机游走：根据随机游走理论，随机生成粒子的移动方向和距离，然后更新粒子的位置。

    5.计算稳定分布：在粒子进行足够多次随机游走后，粒子的分布会趋向于稳定分布。通过计算每个位置上的粒子数，可以得到稳定分布。

    6.绘制图像：根据稳定分布，在图像上绘制相应的形状和颜色，生成所需的图像。

    7. 调整参数：如果生成的图像不符合要求，可以调整扩散模型的参数，重新生成图像，直到满意为止。

需要注意的是，稳定扩散模型生成的图像具有随机性和复杂性，因此需要进行多次实验，以获得更好的结果。同时，由于计算量较大，通常需要使用计算机程序实现。
```

### 过拟合

```python
过拟合现象是指在机器学习中，模型在训练集上表现很好，但在测试集上表现较差的现象。过拟合通常是由于模型过于复杂，而训练数据过少、噪声过多等因素导致的。
神经网络在训练过程中，会根据训练数据调整模型参数，以使得模型在训练集上的损失函数最小。如果模型过于复杂，就有可能出现过拟合现象，即模型过度拟合了训练数据中的噪声和细节，而忽略了数据的本质特征，导致在测试集上表现较差。
过拟合现象的原因可能是由于模型过于复杂，模型参数过多，而训练数据过少，或者训练数据中存在较多的噪声和异常值。此外，如果没有使用正则化技术或者数据增强技术等方法，也容易导致过拟合现象的出现。

为了避免过拟合现象的出现，可以采用一些方法，如正则化技术、dropout技术、数据增强技术等。此外，还可以增加训练数据量、减小模型复杂度等，以提高模型的泛化能力和鲁棒性。
```

### Dropout技术

```python
Dropout技术是一种神经网络正则化方法，旨在减少过拟合的风险。在训练神经网络时，每个神经元都有一定的概率被随机地“丢弃”（即不参与前向传播和反向传播），这样可以使得神经网络不依赖于特定的神经元，从而减少过拟合的风险。
具体来说，Dropout技术可以在每个训练批次中随机地将一些神经元的输出值设置为0，这样可以使得模型的学习过程更加鲁棒，同时还能够减少模型的复杂度。在测试阶段，所有神经元的输出值都会被保留，但是需要将每个神经元的输出值乘以一个概率值，以保持和训练阶段相同的期望输出。
Dropout技术的优点在于可以减少过拟合的风险，提高模型的泛化能力。此外，Dropout技术可以防止神经元之间的共适应，从而使得神经元更加独立，增加了模型的多样性。但是，Dropout技术也可能会影响模型的收敛速度，因此需要在使用时进行适当的调整。
总之，Dropout技术是一种有效的神经网络正则化方法，可以提高模型的泛化能力和鲁棒性，减少过拟合的风险。
```

### Embedding层

``` markdown
对原数据进行升维或降维，原理是矩阵乘法，如：原始图像是10W*20W，使用矩阵乘法乘上一个20W*20的矩阵，转化为10W*20的图像，缩小了10000倍，实现了降维，升维类似。
```

### 卷积层

```python
卷积层是深度学习中最基本的网络层之一，用于提取图像等数据的特征。卷积层通过滑动卷积核在输入数据上进行卷积操作，从而提取出图像中的局部特征。卷积层的参数共享和局部连接的特性可以大大减少模型参数量，从而降低了过拟合的风险。
```

### 池化层

```python
池化层是卷积层之后的一种常用网络层，用于减小特征图的尺寸，同时提高特征的鲁棒性。池化层通常采用最大池化或平均池化的方式，在不改变特征图尺寸的情况下，将每个池化窗口中的最大值或平均值作为输出。这样可以使得特征图具有平移不变性和部分旋转不变性，从而提高模型的泛化能力。
```

### 全连接层

```python
全连接层是深度学习中最常用的网络层之一，用于对特征进行分类或回归。全连接层将卷积层或池化层的输出展平成一维向量，并通过全连接权重进行线性变换，最后输出分类或回归结果。全连接层的参数量较大，容易导致过拟合的风险。
```

### 局部响应归一化层

```python
局部响应归一化层是一种用于增强特征区分度的网络层，可以在卷积层和池化层之间进行插入。该层的作用是对特征图的每个像
```

### 极大似然估计

```python
为什么极大似然估计中对似然函数求导后令导数等于0求出的解是似然函数的极大值解？
	因为常用的概率分布均是指数分布族，指数分布族可以保证似然函数是凸函数，所以求出的极值点是极大值点
```

### 强化学习

```python
当环境可被完全观察到时，强化学习问题被称为马尔可夫决策过程（markov decision process）。 
当状态不依赖于之前的操作时，我们称该问题为上下文赌博机（contextual bandit problem）。 
当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的多臂赌博机（multi-armed bandit problem）。
```

### 反向传播

```python
链式规则（也称为反向传播（backpropagation））一次性调整网络中的全部参数。
```

### 神经网络调参

```markdown
1. 定义：神经网络调参是指在训练神经网络时，通过调整神经网络的超参数和优化算法等参数来提高神经网络的性能和泛化能力的过程。
	神经网络的超参数包括学习率、激活函数、神经元个数、层数、正则化参数等，这些参数的选择会对神经网络的性能和泛化能力产生重要影响。神经网络的优化算法包括梯度下降算法、Adam算法、RMSProp算法等，不同的优化算法有不同的特点和适用场景。
	在神经网络训练过程中，通过调整超参数和优化算法等参数来提高神经网络的性能和泛化能力，需要进行多次实验和验证，以找到最优的参数组合。
	神经网络调参是神经网络训练过程中的重要环节，它可以提高神经网络的性能和泛化能力，使得神经网络在实际应用中更加有效和准确。
```

### 调参方法

```markdown
1. 网格搜索：将超参数的取值范围划分成若干个区间，然后对每个区间进行搜索和实验，最终找到最优的超参数组合。网格搜索的优点是能够保证搜索到全局最优解，但缺点是计算量大，耗时长。

2. 随机搜索：随机选取超参数的值进行实验，可以节省计算资源和时间。随机搜索的优点是能够快速搜索到局部最优解，但缺点是可能会错过全局最优解。

3. 贝叶斯优化：基于贝叶斯定理的优化方法，根据之前的实验结果对超参数进行概率建模，然后选择期望效果最好的超参数组合。贝叶斯优化的优点是能够快速搜索到全局最优解，但缺点是计算量较大。

4. 专家经验：根据专家经验和实际应用场景，选择合适的超参数值，可以快速调整神经网络的性能和泛化能力。

	无论使用哪种方法，都需要进行多次实验和验证，以找到最优的超参数组合。在调整超参数时，不建议直接修改超参数的值，一个一个地尝试，因为这样会花费大量的时间和计算资源。相反，应该根据超参数的特性和实验结果，选择合适的调整范围和步长，以快速找到最优的超参数组合。
```

### 神经网路能够学习任何东西

```markdown
	因为神经网络可以被严格证明是通用函数逼近器，它可以用来逼近任何函数到人们想要的精度（不断添加神经元数量🤣🤣🤣）
	神经网络可以用来近似任何可以用函数表示的东西，一种由输入和输出组成的系统，即只要是：x->f(x)->y，其中x为输入，y为输出，f(x)就是神经网络去逼近的函数。就是只要你能把任何智能行为、任何过程、任何任务、表达成这样的一个函数形式，那么就可以用神经网络去学习它。
	
	补充：神经网络是图灵完备（具有无限的时间和储存空间）的所以它能计算任何可计算问题
```

